from __future__ import annotations

import re
from collections import Counter
from dataclasses import dataclass
from typing import List, Optional

import httpx
from bs4 import BeautifulSoup


UA = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/120.0.0.0 Safari/537.36"
)


@dataclass(frozen=True)
class IndexQuote:
    name: str
    value: float
    change: float
    change_pct: float


@dataclass(frozen=True)
class RisingStock:
    code: str
    name: str
    price: int
    change: int
    change_pct: float
    volume: int
    trade_value: int  # KRW
    market: str  # "KOSPI" | "KOSDAQ"


@dataclass
class StockDetail:
    code: str
    name: str
    price: int
    change: int
    change_pct: float
    volume: int
    trade_value: int
    market: str
    # Pivot data
    pivot: Optional[float] = None
    r1: Optional[float] = None  # 1ì°¨ ì €í•­
    r2: Optional[float] = None  # 2ì°¨ ì €í•­
    s1: Optional[float] = None  # 1ì°¨ ì§€ì§€
    s2: Optional[float] = None  # 2ì°¨ ì§€ì§€
    # Previous day data for pivot calculation
    prev_high: Optional[float] = None
    prev_low: Optional[float] = None
    prev_close: Optional[float] = None
    # News
    news: Optional[List[dict]] = None  # [{"title": str, "date": str, "url": str}]
    # Financial summary - date-keyed dictionary structure
    financials: Optional[dict] = None  # {"2024.12": {"sales": float, "operating_profit": float}, ...}
    # Investor trends
    investor_trends: Optional[List[dict]] = None  # [{"date": str, "institution": int, "foreigner": int, "foreigner_shares": int, "foreigner_ratio": float}]


def _to_int(s: str) -> int:
    """
    Extract the first integer-like token from a mixed string.
    Examples:
      'ìƒí•œê°€ 3,520' -> 3520
      '+1,234' -> 1234
      '-' / 'N/A' -> 0
    """
    s = (s or "").strip()
    if s in ("", "-", "N/A"):
        return 0
    m = re.search(r"[-+]?\d[\d,]*", s)
    if not m:
        return 0
    return int(m.group(0).replace(",", "").replace("+", ""))


def _to_float(s: str) -> float:
    """
    Extract the first float-like token from a mixed string.
    Examples:
      '+29.98%' -> 29.98
      'ì „ì¼ë¹„ 1,234' -> 1234.0
    """
    s = (s or "").strip()
    if s in ("", "-", "N/A"):
        return 0.0
    s = s.replace("%", "")
    m = re.search(r"[-+]?\d[\d,]*(?:\.\d+)?", s)
    if not m:
        return 0.0
    return float(m.group(0).replace(",", "").replace("+", ""))


async def _get(client: httpx.AsyncClient, url: str) -> str:
    r = await client.get(url, follow_redirects=True, timeout=15.0)
    r.raise_for_status()
    # Try to detect encoding, fallback to euc-kr
    if r.encoding is None or r.encoding.lower() in ('iso-8859-1', 'windows-1252'):
        r.encoding = "euc-kr"  # Naver finance commonly uses EUC-KR
    # Ensure proper encoding for Korean text
    try:
        text = r.text
        # Verify encoding by trying to encode/decode
        text.encode('utf-8')
        return text
    except (UnicodeEncodeError, UnicodeDecodeError):
        # If encoding fails, try to fix it
        r.encoding = "euc-kr"
        return r.text


async def fetch_index_quotes(client: httpx.AsyncClient) -> List[IndexQuote]:
    """
    Best-effort parsing for KOSPI/KOSDAQ from `sise_index.naver`.
    This is more stable than the main page and works in headless environments.
    """
    async def fetch_one(code: str) -> Optional[IndexQuote]:
        try:
            html = await _get(client, f"https://finance.naver.com/sise/sise_index.naver?code={code}")
            soup = BeautifulSoup(html, "html.parser")
            now_el = soup.select_one("em#now_value")
            fluc_el = soup.select_one("#change_value_and_rate")
            quo_el = soup.select_one("div#quotient")

            if not now_el:
                return None
            now = _to_float(now_el.get_text(strip=True))

            fluc_txt = fluc_el.get_text(" ", strip=True) if fluc_el else ""
            # Example:
            #  - "13.76 +0.34% ì „ì¼ëŒ€ë¹„"
            #  - "9.19 -0.99% ì „ì¼ëŒ€ë¹„"
            nums = re.findall(r"[-+]?\d[\d,]*(?:\.\d+)?", fluc_txt.replace("%", ""))
            ch = float(nums[0].replace(",", "").replace("+", "")) if len(nums) >= 1 else 0.0
            pct = float(nums[1].replace(",", "").replace("+", "")) if len(nums) >= 2 else 0.0

            # Determine sign via quotient class if available (KOSDAQ uses 'dn')
            cls = quo_el.get("class", []) if quo_el else []
            if "dn" in cls or "down" in cls:
                ch = -abs(ch)
                pct = -abs(pct)
            elif "up" in cls:
                ch = abs(ch)
                pct = abs(pct)
            # else: keep sign from parsed string

            return IndexQuote(code, now, ch, pct)
        except Exception:
            return None

    out: List[IndexQuote] = []
    for code in ("KOSPI", "KOSDAQ"):
        q = await fetch_one(code)
        if q:
            out.append(q)
    return out


async def fetch_rising_stocks(client: httpx.AsyncClient, market: str, limit: int = 50) -> List[RisingStock]:
    """
    Scrape Naver 'ìƒìŠ¹' list.
    market: "KOSPI" -> sosok=0, "KOSDAQ" -> sosok=1
    """
    sosok = "0" if market.upper() == "KOSPI" else "1"
    html = await _get(client, f"https://finance.naver.com/sise/sise_rise.naver?sosok={sosok}")
    soup = BeautifulSoup(html, "html.parser")
    table = soup.select_one("table.type_2")
    if not table:
        return []

    # í—¤ë”ì—ì„œ ì»¬ëŸ¼ ì¸ë±ìŠ¤ ì°¾ê¸°
    thead = table.select_one("thead")
    header_map = {}
    if thead:
        headers = thead.select("th")
        for i, th in enumerate(headers):
            header_text = th.get_text(strip=True)
            if "ì¢…ëª©ëª…" in header_text or "ì¢…ëª©" in header_text:
                header_map["name"] = i
            elif "í˜„ì¬ê°€" in header_text or "ì¢…ê°€" in header_text:
                header_map["price"] = i
            elif "ì „ì¼ë¹„" in header_text or "ë“±ë½" in header_text:
                header_map["change"] = i
            elif "ë“±ë½ë¥ " in header_text or "%" in header_text:
                header_map["change_pct"] = i
            elif "ê±°ë˜ëŸ‰" in header_text:
                header_map["volume"] = i
            elif "ê±°ë˜ëŒ€ê¸ˆ" in header_text:
                header_map["trade_value"] = i
    
    rows = table.select("tr")
    out: List[RisingStock] = []
    for tr in rows:
        tds = tr.find_all("td")
        if len(tds) < 5:
            continue
        a = tr.select_one("a.tltle")
        if not a:
            continue
        name = a.get_text(strip=True)
        href = a.get("href", "")
        m = re.search(r"code=(\d+)", href)
        if not m:
            continue
        code = m.group(1)

        # Filter out ETN, ETF, and special stocks (ìŠ¤í™ì¢…ëª©)
        name_upper = name.upper()
        if any(keyword in name_upper for keyword in ["ETN", "ETF", "ìŠ¤í™", "ìŠ¤íŒ©", "SPAC"]):
            continue

        # í—¤ë” ë§¤ì¹­ìœ¼ë¡œ ì •í™•í•œ ì»¬ëŸ¼ ì°¾ê¸°, ì—†ìœ¼ë©´ ê¸°ë³¸ ì¸ë±ìŠ¤ ì‚¬ìš©
        price_idx = header_map.get("price", 2)
        change_idx = header_map.get("change", 3)
        change_pct_idx = header_map.get("change_pct", 4)
        volume_idx = header_map.get("volume", 5)
        trade_value_idx = header_map.get("trade_value", 8)
        
        price = _to_int(tds[price_idx].get_text(" ", strip=True)) if price_idx < len(tds) else 0
        change = _to_int(tds[change_idx].get_text(" ", strip=True)) if change_idx < len(tds) else 0
        change_pct = _to_float(tds[change_pct_idx].get_text(" ", strip=True)) if change_pct_idx < len(tds) else 0.0
        volume = _to_int(tds[volume_idx].get_text(" ", strip=True)) if volume_idx < len(tds) else 0
        # ê±°ë˜ëŒ€ê¸ˆì€ ë°±ë§Œì› ë‹¨ìœ„ë¡œ í‘œì‹œë˜ë¯€ë¡œ ì› ë‹¨ìœ„ë¡œ ë³€í™˜
        trade_value_raw = tds[trade_value_idx].get_text(" ", strip=True) if trade_value_idx < len(tds) else "0"
        trade_value = _to_int(trade_value_raw) * 1_000_000  # ë°±ë§Œì› â†’ ì›

        out.append(
            RisingStock(
                code=code,
                name=name,
                price=price,
                change=change,
                change_pct=change_pct,
                volume=volume,
                trade_value=trade_value,
                market=market.upper(),
            )
        )
        if len(out) >= limit:
            break
    return out


def calculate_score(stock: RisingStock) -> int:
    """
    Calculate stock score based on multiple factors.
    This will be refined to match original EXE logic exactly.
    
    Factors considered:
    - Change percentage (primary)
    - Trade value (liquidity)
    - Volume (participation)
    - Market (KOSPI vs KOSDAQ)
    """
    base_score = stock.change_pct * 5  # Base: 5 points per 1% change
    
    # Trade value bonus (higher liquidity = higher score)
    if stock.trade_value >= 500000:  # 50ì–µ ì´ìƒ
        base_score += 20
    elif stock.trade_value >= 200000:  # 20ì–µ ì´ìƒ
        base_score += 10
    elif stock.trade_value >= 100000:  # 10ì–µ ì´ìƒ
        base_score += 5
    
    # Volume bonus (high participation)
    if stock.volume >= 50000000:  # 5ì²œë§Œì£¼ ì´ìƒ
        base_score += 15
    elif stock.volume >= 20000000:  # 2ì²œë§Œì£¼ ì´ìƒ
        base_score += 8
    elif stock.volume >= 10000000:  # 1ì²œë§Œì£¼ ì´ìƒ
        base_score += 3
    
    # Market bonus (KOSDAQ tends to be more volatile)
    if stock.market == "KOSDAQ":
        base_score += 2
    
    # Limit-up bonus
    if stock.change_pct >= 29.8:
        base_score += 10
    
    # Cap at 150 (as seen in original)
    return int(min(150, max(0, round(base_score))))


def detect_themes(stocks: List[RisingStock]) -> List[dict]:
    """
    Detect leading themes from stock names and group by common keywords.
    This is a heuristic approach - will be refined based on original EXE logic.
    """
    from collections import Counter
    
    # Common theme keywords in Korean stock market
    theme_keywords = {
        "ë°˜ë„ì²´": ["ë°˜ë„ì²´", "ì¹©", "ì›¨ì´í¼", "ì‹¤ë¦¬ì½˜"],
        "ë°°í„°ë¦¬": ["ë°°í„°ë¦¬", "ì „ì§€", "ë¦¬íŠ¬", "ì—ë„ˆì§€"],
        "ë°”ì´ì˜¤": ["ë°”ì´ì˜¤", "ì œì•½", "ì˜ë£Œ", "ë°”ì´ì˜¤í…", "ì œì•½ë°”ì´ì˜¤"],
        "AI": ["AI", "ì¸ê³µì§€ëŠ¥", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹"],
        "ì „ê¸°ì°¨": ["ì „ê¸°ì°¨", "ì „ê¸°", "EV", "ì „ë™ì°¨"],
        "2ì°¨ì „ì§€": ["2ì°¨ì „ì§€", "ì´ì°¨ì „ì§€", "ë°°í„°ë¦¬"],
        "ê²Œì„": ["ê²Œì„", "ì—”í„°í…Œì¸ë¨¼íŠ¸"],
        "ì¦ê¶Œ": ["ì¦ê¶Œ", "íˆ¬ì", "ê¸ˆìœµ"],
        "ê±´ì„¤": ["ê±´ì„¤", "ì‹œê³µ", "í† ëª©"],
        "í™”í•™": ["í™”í•™", "ì„ìœ í™”í•™"],
        "ì² ê°•": ["ì² ê°•", "ì œì² "],
        "IT": ["IT", "ì†Œí”„íŠ¸ì›¨ì–´", "ì‹œìŠ¤í…œ"],
    }
    
    # Count theme occurrences in top stocks
    theme_counts: Counter[str] = Counter()
    theme_stocks: dict[str, List[RisingStock]] = {}
    
    for stock in stocks:
        name = stock.name
        matched_themes = []
        
        for theme, keywords in theme_keywords.items():
            if any(kw in name for kw in keywords):
                matched_themes.append(theme)
                if theme not in theme_stocks:
                    theme_stocks[theme] = []
                theme_stocks[theme].append(stock)
        
        # If no theme matched, check for common suffixes
        if not matched_themes:
            if name.endswith("ì¦ê¶Œ") or name.endswith("ì¦ê¶Œìš°"):
                theme_counts["ì¦ê¶Œ"] += 1
                if "ì¦ê¶Œ" not in theme_stocks:
                    theme_stocks["ì¦ê¶Œ"] = []
                theme_stocks["ì¦ê¶Œ"].append(stock)
    
    # Calculate theme scores (weighted by stock performance)
    theme_scores: list[tuple[str, float, int]] = []
    for theme, theme_stock_list in theme_stocks.items():
        if len(theme_stock_list) >= 2:  # At least 2 stocks to form a theme
            avg_change = sum(s.change_pct for s in theme_stock_list) / len(theme_stock_list)
            total_trade_value = sum(s.trade_value for s in theme_stock_list)
            # Score = (number of stocks) * (avg change %) * (log of total trade value)
            score = len(theme_stock_list) * avg_change * (1 + (total_trade_value / 1000000) ** 0.3)
            theme_scores.append((theme, score, len(theme_stock_list)))
    
    # Sort by score and return top 5
    theme_scores.sort(key=lambda x: x[1], reverse=True)
    
    return [
        {
            "name": theme,
            "count": count,
            "score": round(score, 2),
        }
        for theme, score, count in theme_scores[:5]
    ]


def signals_for(s: RisingStock) -> list[dict]:
    """
    Generate trading signals based on stock performance.
    Comprehensive signal patterns matching original EXE logic.
    
    Signal Patterns:
    1. ğŸ”’ ìƒí•œê°€ í™€ë”© / ë§¤ìˆ˜ ê¸ˆì§€ - ìƒí•œê°€(29.8%+) êµ¬ê°„
    2. âš¡ ëŒíŒŒ ë§¤ë§¤ - ê°•í•œ ìƒìŠ¹ì„¸(20%+) ëŒíŒŒ êµ¬ê°„
    3. ğŸ§² ëˆŒë¦¼ëª© ë§¤ìˆ˜ - ì¡°ì • í›„ ì¬ìƒìŠ¹ ê¸°íšŒ(12%+)
    4. ğŸ‘€ ê³ ê°€ ë†€ì´ - ë³´í•©ì„¸, ìˆ˜ê¸‰ í™•ì¸ í•„ìš”(5-12%)
    5. ğŸ“Š ì¶”ì„¸ ì¶”ì¢… - ì•ˆì •ì  ìƒìŠ¹ ì¶”ì„¸(5% ë¯¸ë§Œ)
    6. ğŸ’° ì°¨ìµ ì‹¤í˜„ ë§¤ë¬¼ ì¶œíšŒ(ê´€ë§) - ê³ ê°€ëŒ€ ê±°ë˜ëŸ‰ ì¦ê°€, ì¡°ì • ê°€ëŠ¥ì„±
    7. ğŸ“ˆ ê±°ë˜ëŸ‰ ê¸‰ì¦ - ê±°ë˜ëŸ‰ í­ì¦ ì‹ í˜¸
    """
    sigs: list[dict] = []
    
    # Limit-up detection (ìƒí•œê°€)
    if s.change_pct >= 29.8:
        sigs.append({"title": "ğŸ”’ ìƒí•œê°€ í™€ë”© / ë§¤ìˆ˜ ê¸ˆì§€", "desc": "ìƒí•œê°€", "tone": "bad"})
        # Calculate stop-loss (7% below current price for limit-up)
        stop_loss = int(s.price * 0.93)
        if s.trade_value >= 200000:  # 20ì–µ ì´ìƒ = ê±°ë˜ëŒ€ê¸ˆ í­ë°œ
            sigs.append({"title": f"âš¡ ëŒíŒŒ ë§¤ë§¤ (ì†ì ˆ {stop_loss:,}ì›)", "desc": "ê¸‰ë“±, ê±°ë˜ëŒ€ê¸ˆ í­ë°œ", "tone": "warn"})
        else:
            sigs.append({"title": f"âš¡ ëŒíŒŒ ë§¤ë§¤ (ì†ì ˆ {stop_loss:,}ì›)", "desc": "ê¸‰ë“±, ëª¨ë©˜í…€ ìˆ˜ê¸‰", "tone": "warn"})
    
    # Strong breakout (20%+ but not limit-up)
    elif s.change_pct >= 20:
        stop_loss = int(s.price * 0.95)  # 5% stop-loss for strong moves
        if s.trade_value >= 200000:  # 20ì–µ ì´ìƒ
            sigs.append({"title": f"âš¡ ëŒíŒŒ ë§¤ë§¤ (ì†ì ˆ {stop_loss:,}ì›)", "desc": "ê¸‰ë“±, ê±°ë˜ëŒ€ê¸ˆ í­ë°œ", "tone": "warn"})
        else:
            sigs.append({"title": f"âš¡ ëŒíŒŒ ë§¤ë§¤ (ì†ì ˆ {stop_loss:,}ì›)", "desc": "ê¸‰ë“±, ëª¨ë©˜í…€ ìˆ˜ê¸‰", "tone": "warn"})
    
    # Pullback entry opportunity (12%+)
    elif s.change_pct >= 12:
        sigs.append({"title": "ğŸ§² ëˆŒë¦¼ëª© ë§¤ìˆ˜ (ë¶„í•  ì§„ì…)", "desc": "ê°•ì„¸, ê±°ë˜ëŒ€ê¸ˆ í™•ì¸", "tone": "ok"})
    
    # Moderate strength (5-12%)
    elif s.change_pct >= 5:
        # Check for profit-taking signals (high volume at high price)
        if s.volume >= 15000000 and s.trade_value >= 150000:  # ê³ ê°€ëŒ€ ê±°ë˜ëŸ‰ ì¦ê°€
            sigs.append({"title": "ğŸ’° ì°¨ìµ ì‹¤í˜„ ë§¤ë¬¼ ì¶œíšŒ(ê´€ë§)", "desc": "ê³ ê°€ëŒ€ ê±°ë˜ëŸ‰ ì¦ê°€, ì¡°ì • ê°€ëŠ¥ì„±", "tone": "neutral"})
        else:
            sigs.append({"title": "ğŸ‘€ ê³ ê°€ ë†€ì´ (ìˆ˜ê¸‰ í™•ì¸)", "desc": "ê°•ì„¸, ë³€ë™ì„± ìœ ì˜", "tone": "neutral"})
    
    # Stable uptrend (0-5%)
    elif s.change_pct > 0:
        if s.volume >= 10000000 and s.trade_value >= 100000:  # ì•ˆì •ì  ìƒìŠ¹ ì¶”ì„¸
            sigs.append({"title": "ğŸ“Š ì¶”ì„¸ ì¶”ì¢…", "desc": "ì•ˆì •ì  ìƒìŠ¹ ì¶”ì„¸, ì§€ì† ëª¨ë‹ˆí„°ë§", "tone": "ok"})
        else:
            sigs.append({"title": "ğŸ‘€ ê³ ê°€ ë†€ì´ (ìˆ˜ê¸‰ í™•ì¸)", "desc": "ë³´í•©ì„¸, ìˆ˜ê¸‰ í™•ì¸ í•„ìš”", "tone": "neutral"})
    
    # Negative or flat
    else:
        sigs.append({"title": "ğŸ‘€ ê³ ê°€ ë†€ì´ (ìˆ˜ê¸‰ í™•ì¸)", "desc": "ë³´í•©ì„¸, ìˆ˜ê¸‰ í™•ì¸ í•„ìš”", "tone": "neutral"})

    # Volume surge indicator (applies to all cases)
    if s.volume >= 20000000:  # 2ì²œë§Œì£¼ ì´ìƒ
        sigs.append({"title": "ğŸ“ˆ ê±°ë˜ëŸ‰ ê¸‰ì¦", "desc": "ìˆ˜ê¸‰ ë³€ë™ì„± í™•ëŒ€", "tone": "neutral"})
    
    return sigs[:6]


def ai_opinion_for(s: RisingStock, detail: Optional[StockDetail] = None) -> str:
        """
        Generate comprehensive AI investment opinion based on multiple factors.
        Enhanced with detailed news analysis, technical indicators, financials, and investor trends.
        """
        parts = []
        
        # === 1. Market Context & Overall Assessment ===
        market_context = []
        if s.change_pct >= 29.8:
            market_context.append("**ìƒí•œê°€ êµ¬ê°„**")
        elif s.change_pct >= 20:
            market_context.append("**ê¸‰ë“± êµ¬ê°„**")
        elif s.change_pct >= 12:
            market_context.append("**ê°•ì„¸ íë¦„**")
        elif s.change_pct >= 5:
            market_context.append("**ì¤‘ê°„ ê°•ì„¸**")
        else:
            market_context.append("**ë³´í•©ì„¸**")
        
        if s.trade_value >= 500000:  # 50ì–µ ì´ìƒ
            market_context.append("ê±°ë˜ëŒ€ê¸ˆì´ **í­ë°œì ìœ¼ë¡œ ì¦ê°€**")
        elif s.trade_value >= 200000:  # 20ì–µ ì´ìƒ
            market_context.append("ê±°ë˜ëŒ€ê¸ˆì´ **í¬ê²Œ ì¦ê°€**")
        elif s.trade_value >= 100000:  # 10ì–µ ì´ìƒ
            market_context.append("ê±°ë˜ëŒ€ê¸ˆì´ **í™œë°œ**")
        
        if s.volume >= 50000000:  # 5ì²œë§Œì£¼ ì´ìƒ
            market_context.append("ê±°ë˜ëŸ‰ì´ **í­ì¦**")
        elif s.volume >= 20000000:  # 2ì²œë§Œì£¼ ì´ìƒ
            market_context.append("ê±°ë˜ëŸ‰ì´ **ëŒ€í­ ì¦ê°€**")
        elif s.volume >= 10000000:  # 1ì²œë§Œì£¼ ì´ìƒ
            market_context.append("ê±°ë˜ëŸ‰ì´ **í™œë°œ**")
        
        if market_context:
            parts.append(f"í˜„ì¬ {', '.join(market_context)}í•œ ìƒíƒœì…ë‹ˆë‹¤.")
        
        # === 2. Investor Trend Analysis (Detailed) ===
        if detail and detail.investor_trends and len(detail.investor_trends) > 0:
            latest = detail.investor_trends[0]
            if isinstance(latest, dict):
                foreigner_val = latest.get("foreigner", 0)
                institution_val = latest.get("institution", 0)
            else:
                foreigner_val = getattr(latest, "foreigner", 0) if hasattr(latest, "foreigner") else 0
                institution_val = getattr(latest, "institution", 0) if hasattr(latest, "institution") else 0
            
            investor_analysis = []
            if foreigner_val > 200000:  # ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ 2ì–µ ì´ìƒ
                investor_analysis.append("**ì™¸êµ­ì¸ì´ ê°•ë ¥í•œ ë§¤ìˆ˜ì„¸**ë¥¼ ë³´ì´ê³  ìˆì–´")
            elif foreigner_val > 100000:  # ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ 1ì–µ ì´ìƒ
                investor_analysis.append("**ì™¸êµ­ì¸ì´ ë§¤ìˆ˜ì„¸ë¥¼ ì£¼ë„**í•˜ê³  ìˆì–´")
            elif foreigner_val < -200000:  # ì™¸êµ­ì¸ ìˆœë§¤ë„ 2ì–µ ì´ìƒ
                investor_analysis.append("**ì™¸êµ­ì¸ ë§¤ë„ì„¸ê°€ ê°•í•˜ê²Œ ì§€ì†**ë˜ì–´")
            elif foreigner_val < -100000:  # ì™¸êµ­ì¸ ìˆœë§¤ë„ 1ì–µ ì´ìƒ
                investor_analysis.append("ì™¸êµ­ì¸ ë§¤ë„ì„¸ê°€ ì§€ì†ë˜ì–´")
            
            if institution_val > 200000:  # ê¸°ê´€ ìˆœë§¤ìˆ˜ 2ì–µ ì´ìƒ
                investor_analysis.append("**ê¸°ê´€ë„ ëŒ€ê·œëª¨ ë§¤ìˆ˜**ì— ë‚˜ì„œ")
            elif institution_val > 100000:  # ê¸°ê´€ ìˆœë§¤ìˆ˜ 1ì–µ ì´ìƒ
                investor_analysis.append("ê¸°ê´€ë„ ë§¤ìˆ˜ì„¸ë¥¼ ë³´ì´ë©°")
            elif institution_val < -200000:  # ê¸°ê´€ ìˆœë§¤ë„ 2ì–µ ì´ìƒ
                investor_analysis.append("**ê¸°ê´€ì´ ëŒ€ê·œëª¨ ë§¤ë„**ì— ë‚˜ì„œ")
            elif institution_val < -100000:  # ê¸°ê´€ ìˆœë§¤ë„ 1ì–µ ì´ìƒ
                investor_analysis.append("ê¸°ê´€ ë§¤ë„ì„¸ê°€ ì§€ì†ë˜ì–´")
            
            if investor_analysis:
                parts.append(" ".join(investor_analysis) + " ì£¼ê°€ ì›€ì§ì„ì— ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        # === 3. News Analysis (Enhanced) ===
        if detail and detail.news and len(detail.news) > 0:
            news_list = detail.news if isinstance(detail.news, list) else []
            news_titles = " ".join([(n.get("title", "") if isinstance(n, dict) else str(n)) for n in news_list[:5]])
            news_text = news_titles.lower()
            
            # ê¸ì •ì  í‚¤ì›Œë“œ
            positive_keywords = ["ì¸ê¸° ê²€ìƒ‰", "ê²€ìƒ‰ ì¢…ëª©", "ê¸‰ë“±", "ìƒí•œê°€", "êµ¬ì¡°ëŒ€", "ì™”ë‹¤", "ìƒìŠ¹", "í˜¸ì¬", 
                               "ì‹¤ì ", "ìˆ˜ì£¼", "ê³„ì•½", "ìŠ¹ì¸", "ì¸í—ˆê°€", "ì‹ ì•½", "ê°œë°œ", "ì„±ê³µ", "ëŒíŒŒ"]
            # ë¶€ì •ì  í‚¤ì›Œë“œ
            negative_keywords = ["í•˜ë½", "ê¸‰ë½", "ë¶€ì§„", "ì‹¤ì ", "ì ì", "ì†ì‹¤", "ê²½ê³ ", "ì£¼ì˜", "ë¦¬ì½œ", "ì¡°ì‚¬"]
            
            positive_count = sum(1 for kw in positive_keywords if kw in news_text)
            negative_count = sum(1 for kw in negative_keywords if kw in news_text)
            
            if "ì¸ê¸° ê²€ìƒ‰" in news_titles or "ê²€ìƒ‰ ì¢…ëª©" in news_titles:
                parts.append("ì£¼ê°€ ìƒìŠ¹ì˜ ì£¼ìš” íŠ¸ë¦¬ê±°ëŠ” **'ì¸ê¸° ê²€ìƒ‰ ì¢…ëª©'** ê´€ë ¨ ì´ìŠˆë¡œ íŒë‹¨ë˜ë©°, ë‹¨ê¸° ëª¨ë©˜í…€ì´ ê°•í•©ë‹ˆë‹¤.")
            elif positive_count >= 2:
                parts.append("ìµœê·¼ ë‰´ìŠ¤ì—ì„œ **ê¸ì •ì  ì´ìŠˆê°€ ë‹¤ìˆ˜ í™•ì¸**ë˜ì–´ ì£¼ê°€ì— í˜¸ì¬ë¡œ ì‘ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
            elif negative_count >= 2:
                parts.append("ìµœê·¼ ë‰´ìŠ¤ì—ì„œ **ë¶€ì •ì  ì´ìŠˆê°€ í™•ì¸**ë˜ì–´ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            elif positive_count > 0:
                parts.append("ìµœê·¼ ë‰´ìŠ¤ ì´ìŠˆê°€ ì£¼ê°€ì— **ê¸ì •ì  ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤**.")
            elif len(news_list) > 0:
                parts.append("ë‰´ìŠ¤ ì´ìŠˆë¥¼ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        
        # === 4. Technical Analysis (Comprehensive) ===
        if detail and detail.pivot and detail.price:
            current = detail.price
            pivot = detail.pivot
            
            # Pivot position analysis
            if detail.r2 and current >= detail.r2 * 0.98:
                parts.append("ê¸°ìˆ ì ìœ¼ë¡œ **2ì°¨ ì €í•­ì„ (R2)ì„ ëŒíŒŒ**í•œ ë§¤ìš° ê°•í•œ ìƒìŠ¹ êµ¬ê°„ì…ë‹ˆë‹¤.")
                if s.change_pct >= 20:
                    parts.append("ë‹¨ê¸° ê³¼ì—´ êµ¬ê°„ì— ì§„ì…í–ˆìœ¼ë¯€ë¡œ **ì¶”ê²©ë§¤ìˆ˜ëŠ” ìœ„í—˜**í•˜ë©°, ë³´ìœ ìëŠ” ë¶„í•  ì²­ì‚°ì„ ê³ ë ¤í•˜ì„¸ìš”.")
                else:
                    parts.append("ì¶”ê°€ ìƒìŠ¹ ì—¬ë ¥ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë‚˜, **ë³€ë™ì„±ê³¼ ì¡°ì • ê°€ëŠ¥ì„±**ì— ì£¼ì˜í•˜ì„¸ìš”.")
            elif detail.r1 and current >= detail.r1 * 0.98:
                parts.append("**1ì°¨ ì €í•­ì„ (R1) ê·¼ì²˜**ì—ì„œ ì €í•­ì„ ë°›ì„ ìˆ˜ ìˆìœ¼ë©°, ëŒíŒŒ ì—¬ë¶€ê°€ ê´€ê±´ì…ë‹ˆë‹¤.")
                if s.trade_value >= 200000:
                    parts.append("ê±°ë˜ëŒ€ê¸ˆì´ ì¶©ë¶„í•˜ì—¬ ëŒíŒŒ ê°€ëŠ¥ì„±ì´ ìˆìœ¼ë‚˜, ì‹¤íŒ¨ ì‹œ ì¡°ì • ê°€ëŠ¥ì„±ë„ ìˆìŠµë‹ˆë‹¤.")
            elif current >= pivot * 0.98:
                parts.append("**Pivot Point ê·¼ì²˜**ì—ì„œ ì›€ì§ì´ê³  ìˆìœ¼ë©°, ë°©í–¥ì„± í™•ë¦½ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            elif detail.s1 and current <= detail.s1 * 1.02:
                parts.append("**1ì°¨ ì§€ì§€ì„ (S1) ê·¼ì²˜**ì—ì„œ ì§€ì§€ë¥¼ ë°›ê³  ìˆì–´ í•˜ë½ ë°©ì–´ë ¥ì´ ìˆìŠµë‹ˆë‹¤.")
                if s.change_pct > 0:
                    parts.append("ì§€ì§€ì„ ì—ì„œ ë°˜ë“±í•  ê²½ìš° ì¶”ê°€ ìƒìŠ¹ ì—¬ë ¥ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            elif detail.s2 and current <= detail.s2 * 1.02:
                parts.append("**2ì°¨ ì§€ì§€ì„ (S2) ê·¼ì²˜**ì— ìœ„ì¹˜í•˜ì—¬ ê°•í•œ ì§€ì§€ëŒ€ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        # === 5. Financial Analysis ===
        if detail and detail.financials and len(detail.financials) > 0:
            financial_list = detail.financials if isinstance(detail.financials, list) else []
            if len(financial_list) > 0:
                latest_fin = financial_list[0]
                if isinstance(latest_fin, dict):
                    sales = latest_fin.get("sales", 0)
                    operating_profit = latest_fin.get("operating_profit", 0)
                else:
                    sales = getattr(latest_fin, "sales", 0) if hasattr(latest_fin, "sales") else 0
                    operating_profit = getattr(latest_fin, "operating_profit", 0) if hasattr(latest_fin, "operating_profit") else 0
                
                if operating_profit > 0 and sales > 0:
                    margin = (operating_profit / sales) * 100
                    if margin >= 20:
                        parts.append("**ì¬ë¬´ ê±´ì „ì„±ì´ ìš°ìˆ˜**í•˜ë©° ì˜ì—…ì´ìµë¥ ì´ ë†’ì•„ ì•ˆì •ì ì¸ ê¸°ì—…ì…ë‹ˆë‹¤.")
                    elif margin >= 10:
                        parts.append("ì¬ë¬´ ìƒíƒœê°€ ì–‘í˜¸í•˜ë©° ìˆ˜ìµì„±ì´ ì•ˆì •ì ì…ë‹ˆë‹¤.")
                    elif margin < 0:
                        parts.append("**ì¬ë¬´ ìƒíƒœì— ì£¼ì˜**ê°€ í•„ìš”í•˜ë©°, ì‹¤ì  ê°œì„  ì—¬ë¶€ë¥¼ ì§€ì† ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”.")
        
        # === 6. Risk Assessment & Trading Strategy ===
        risk_parts = []
        
        if s.change_pct >= 29.8:
            risk_parts.append("**ìƒí•œê°€ êµ¬ê°„**ì´ë¯€ë¡œ ì¶”ê²©ë§¤ìˆ˜ëŠ” ë§¤ìš° ìœ„í—˜í•©ë‹ˆë‹¤.")
            if s.trade_value >= 200000:
                risk_parts.append("ê±°ë˜ëŒ€ê¸ˆì´ í­ë°œì ìœ¼ë¡œ ì¦ê°€í–ˆìœ¼ë‚˜, ì´ëŠ” ê³¼ì—´ ì‹ í˜¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            risk_parts.append("ë³´ìœ ìëŠ” **ë³€ë™ì„±ì— ëŒ€ë¹„í•´ ë¶„í•  ì²­ì‚°/ì†ì ˆ ê¸°ì¤€ì„ ëª…í™•íˆ** í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        elif s.change_pct >= 20:
            risk_parts.append("**ê¸‰ë“± êµ¬ê°„**ì´ë¯€ë¡œ ì¶”ê°€ ìˆ˜ê¸‰ ìœ ì…ì„ í™•ì¸í•˜ë©´ì„œ **ì†ì ˆ ë¼ì¸ì„ ë¨¼ì € ì •í•˜ëŠ” ê²ƒ**ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.")
            if s.trade_value >= 200000:
                risk_parts.append("ê±°ë˜ëŒ€ê¸ˆì´ í¬ê²Œ ì¦ê°€í•˜ì—¬ ëª¨ë©˜í…€ì´ ê°•í•˜ì§€ë§Œ, ì¡°ì • ê°€ëŠ¥ì„±ë„ ìˆìŠµë‹ˆë‹¤.")
        elif s.change_pct >= 12:
            risk_parts.append("**ê°•ì„¸ íë¦„**ì´ ì§€ì†ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
            if s.volume >= 10000000:
                risk_parts.append("ê±°ë˜ëŸ‰ì´ í™œë°œí•˜ì—¬ ìœ ë™ì„±ì´ ì¢‹ìŠµë‹ˆë‹¤.")
            risk_parts.append("**ëˆŒë¦¼ êµ¬ê°„ì—ì„œ ë¶„í•  ì§„ì…**ì„ ê³ ë ¤í•˜ë˜, ê±°ë˜ëŒ€ê¸ˆì´ ìœ ì§€ë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        elif s.change_pct >= 5:
            risk_parts.append("**ì¤‘ê°„ ê°•ì„¸** êµ¬ê°„ì…ë‹ˆë‹¤.")
            risk_parts.append("ë‰´ìŠ¤ì™€ ìˆ˜ê¸‰ ë³€í™”ë¥¼ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ë©°, **ì¶”ì„¸ê°€ ì§€ì†ë˜ëŠ”ì§€ í™•ì¸**í•˜ì„¸ìš”.")
        else:
            risk_parts.append("**ë‹¨ê¸° ë³€ë™ì„±ì´ ë‚®ì€ í¸**ì…ë‹ˆë‹¤.")
            risk_parts.append("ë‰´ìŠ¤/ìˆ˜ê¸‰ ë³€í™”ë¥¼ í™•ì¸í•˜ë©° **ë³´ìˆ˜ì ìœ¼ë¡œ ì ‘ê·¼**í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        
        if risk_parts:
            parts.append(" ".join(risk_parts))
        
        # === 7. Market-Specific Considerations ===
        if s.market == "KOSDAQ":
            if s.change_pct >= 20:
                parts.append("ì½”ìŠ¤ë‹¥ íŠ¹ì„±ìƒ **ë³€ë™ì„±ì´ í¬ë¯€ë¡œ ë¦¬ìŠ¤í¬ ê´€ë¦¬**ê°€ íŠ¹íˆ ì¤‘ìš”í•©ë‹ˆë‹¤.")
        elif s.market == "KOSPI":
            if s.change_pct >= 20:
                parts.append("ì½”ìŠ¤í”¼ ëŒ€í˜•ì£¼ íŠ¹ì„±ìƒ **ì•ˆì •ì„±ì€ ë†’ìœ¼ë‚˜ ìƒìŠ¹ ëª¨ë©˜í…€ ì§€ì† ì—¬ë¶€**ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        # === Final Summary ===
        if not parts:
            return "ë¶„ì„ ì¤‘..."
        
        return " ".join(parts)


async def build_snapshot(client: httpx.AsyncClient) -> dict:
    indices = await fetch_index_quotes(client)
    kospi_rise = await fetch_rising_stocks(client, "KOSPI", limit=80)
    kosdaq_rise = await fetch_rising_stocks(client, "KOSDAQ", limit=80)
    merged = kospi_rise + kosdaq_rise
    # Sort by Score (not just change_pct) to consider liquidity and participation
    merged.sort(key=lambda x: calculate_score(x), reverse=True)
    top30 = merged[:30]
    
    # Detect themes from all rising stocks (not just top30)
    all_rising = kospi_rise + kosdaq_rise
    themes = detect_themes(all_rising)

    return {
        "indices": [
            {"name": q.name, "value": q.value, "change": q.change, "change_pct": q.change_pct} for q in indices
        ],
        "themes": themes,
        "stocks": [
            {
                "code": s.code,
                "name": s.name,
                "market": s.market,
                "price": s.price,
                "change": s.change,
                "change_pct": s.change_pct,
                "volume": s.volume,
                "trade_value": s.trade_value,
                "link": f"https://finance.naver.com/item/main.naver?code={s.code}",
                "score": calculate_score(s),  # Improved scoring based on multiple factors
                "signals": signals_for(s),
                "ai_opinion": ai_opinion_for(s, None),  # Basic opinion, will be enhanced with detail in modal
            }
            for s in top30
        ],
        "source": "naver_finance",
    }


def calculate_pivot_points(high: float, low: float, close: float) -> dict:
    """
    Calculate Pivot Point and support/resistance levels.
    Standard pivot point formula:
    - Pivot = (High + Low + Close) / 3
    - R1 = 2 * Pivot - Low
    - R2 = Pivot + (High - Low)
    - S1 = 2 * Pivot - High
    - S2 = Pivot - (High - Low)
    """
    pivot = (high + low + close) / 3
    r1 = 2 * pivot - low
    r2 = pivot + (high - low)
    s1 = 2 * pivot - high
    s2 = pivot - (high - low)
    return {
        "pivot": round(pivot, 0),
        "r1": round(r1, 0),
        "r2": round(r2, 0),
        "s1": round(s1, 0),
        "s2": round(s2, 0),
    }


async def fetch_stock_detail(client: httpx.AsyncClient, code: str) -> Optional[StockDetail]:
    """
    Fetch detailed information for a specific stock from Naver Finance.
    Includes: pivot points, news, financials, investor trends.
    """
    try:
        # Main stock page
        html = await _get(client, f"https://finance.naver.com/item/main.naver?code={code}")
        soup = BeautifulSoup(html, "html.parser")
        
        # Debug: log if page loaded
        if not soup:
            print(f"Warning: Failed to parse HTML for {code}")
            return None
        
        # Basic info
        name_el = soup.select_one("h2.wrap_company a")
        name = name_el.get_text(strip=True) if name_el else ""
        
        # Current price and change
        no_today = soup.select_one("p.no_today")
        price = 0
        change = 0
        change_pct = 0.0
        if no_today:
            price_el = no_today.select_one("span.blind")
            if price_el:
                price = _to_int(price_el.get_text(strip=True))
            
            # Change
            change_el = soup.select_one("span.blind.sptxt")
            if change_el:
                change_text = change_el.find_next_sibling()
                if change_text:
                    change = _to_int(change_text.get_text(strip=True))
                    # Determine sign from parent class
                    parent = change_el.parent
                    if parent and "down" in parent.get("class", []):
                        change = -abs(change)
            
            # Change percentage
            pct_el = soup.select_one("span.blind.sptxt")
            if pct_el:
                pct_text = pct_el.find_next_sibling()
                if pct_text:
                    change_pct = _to_float(pct_text.get_text(strip=True))
                    if change < 0:
                        change_pct = -abs(change_pct)
        
        # Volume and trade value
        volume = 0
        trade_value = 0
        
        # Parse trade value from table row with <th class="title">ê±°ë˜ëŒ€ê¸ˆ(ë°±ë§Œ)</th> and <span id="_amount">
        # <th class="title">ê±°ë˜ëŒ€ê¸ˆ(ë°±ë§Œ)</th><td class="num"><span id="_amount">693</span></td>
        # ì´ë¯¸ ë°±ë§Œ ë‹¨ìœ„ì´ë¯€ë¡œ 1,000,000 ê³±í•˜ê¸°
        all_tables_for_amount = soup.select("table")
        for table in all_tables_for_amount:
            rows = table.select("tr")
            for row in rows:
                th = row.select_one("th.title, th")
                if th:
                    th_text = th.get_text(strip=True)
                    # "ê±°ë˜ëŒ€ê¸ˆ"ì´ í¬í•¨ë˜ì–´ ìˆê³  "(ë°±ë§Œ)" ë‹¨ìœ„ê°€ ëª…ì‹œëœ ê²½ìš°
                    if "ê±°ë˜ëŒ€ê¸ˆ" in th_text and ("ë°±ë§Œ" in th_text or "(ë°±ë§Œ)" in th_text):
                        td = row.select_one("td")
                        if td:
                            amount_span = td.select_one("span#_amount")
                            if amount_span:
                                amount_text = amount_span.get_text(strip=True)
                                amount_value = _to_int(amount_text)
                                if amount_value > 0:
                                    # ë°±ë§Œ ë‹¨ìœ„ì´ë¯€ë¡œ 1,000,000 ê³±í•˜ê¸°
                                    trade_value = amount_value * 1_000_000
                                    break  # ì°¾ì•˜ìœ¼ë©´ ì¤‘ë‹¨
            if trade_value > 0:
                break  # ì°¾ì•˜ìœ¼ë©´ í…Œì´ë¸” ê²€ìƒ‰ ì¤‘ë‹¨
        
        # Parse volume from table structure
        # ê±°ë˜ëŸ‰: <span class="sptxt sp_txt9">ê±°ë˜ëŸ‰</span> ë‹¤ìŒ <em> íƒœê·¸ ì•ˆì˜ ìˆ«ìë“¤
        # ê±°ë˜ëŒ€ê¸ˆ: <span class="sptxt sp_txt10">ê±°ë˜ëŒ€ê¸ˆ</span> ë‹¤ìŒ <em> íƒœê·¸ ì•ˆì˜ ìˆ«ìë“¤, ê·¸ë¦¬ê³  <em> ë‹¤ìŒ <span class="sptxt sp_txt11">ë°±ë§Œ</span>
        # í˜¸ê°€ ì •ë³´ í…Œì´ë¸”ì€ ì œì™¸í•´ì•¼ í•¨ (summary="í˜¸ê°€ ì •ë³´ì— ê´€í•œí‘œì…ë‹ˆë‹¤.")
        summary_table = None
        all_tables = soup.select("table.type_2, table.type_tax, table.no_info")
        for table in all_tables:
            # í˜¸ê°€ ì •ë³´ í…Œì´ë¸” ì œì™¸
            table_summary = table.get("summary", "")
            if "í˜¸ê°€ ì •ë³´" in table_summary or "í˜¸ê°€ì •ë³´" in table_summary:
                continue
            # "ì£¼ìš” ì‹œì„¸" ë˜ëŠ” "ì‹œì„¸" ê´€ë ¨ í…Œì´ë¸” ìš°ì„  ì„ íƒ
            if "ì£¼ìš” ì‹œì„¸" in table_summary or "ì‹œì„¸" in table_summary or "ê±°ë˜ëŒ€ê¸ˆ" in table_summary:
                summary_table = table
                break
        # ìœ„ì—ì„œ ì°¾ì§€ ëª»í–ˆìœ¼ë©´ í˜¸ê°€ ì •ë³´ê°€ ì•„ë‹Œ ì²« ë²ˆì§¸ í…Œì´ë¸” ì‚¬ìš©
        if not summary_table:
            for table in all_tables:
                table_summary = table.get("summary", "")
                if "í˜¸ê°€ ì •ë³´" not in table_summary and "í˜¸ê°€ì •ë³´" not in table_summary:
                    summary_table = table
                    break
        
        if summary_table and trade_value == 0:
            rows = summary_table.select("tr")
            for row in rows:
                # Find "ê±°ë˜ëŸ‰" or "ê±°ë˜ëŒ€ê¸ˆ" label
                label_span = row.select_one("span.sptxt")
                if label_span:
                    label_text = label_span.get_text(strip=True)
                    td = row.select_one("td")
                    if td:
                        # Find <em> tag after the label
                        em_tag = td.select_one("em")
                        if em_tag:
                            # Extract number from <em> tag - get all text (handles both blind and noX spans)
                            # ì´ë¯¸ì§€ êµ¬ì¡°: <em> ì•ˆì— <span class="no4">4</span><span class="no2">2</span>... í˜•íƒœ
                            number_text = em_tag.get_text(strip=True)
                            number_value = _to_int(number_text)
                            
                            if "ê±°ë˜ëŸ‰" in label_text and volume == 0:
                                volume = number_value
                        
                        # Early exit if found
                        if volume > 0:
                            break
        
        # Method 3: Fallback to ID-based parsing for volume
        if volume == 0:
            quant_el = soup.select_one("span#_quant")
            if quant_el:
                volume = _to_int(quant_el.get_text(strip=True))
        
        # Market detection (KOSPI vs KOSDAQ)
        market = "KOSPI"
        if "ì½”ìŠ¤ë‹¥" in html or "kosdaq" in html.lower():
            market = "KOSDAQ"
        
        # Previous day data for pivot (ê³ ê°€/ì €ê°€/ì¢…ê°€) - optimized for speed
        prev_high = None
        prev_low = None
        prev_close = None
        
        # Fast path: Try summary table first (most common location)
        if summary_table:
            rows = summary_table.select("tr")
            for row in rows:
                th = row.select_one("th")
                if th:
                    th_text = th.get_text(strip=True)
                    td = row.select_one("td")
                    if td:
                        td_text = td.get_text(strip=True)
                        if "ì „ì¼" in th_text:
                            if "ê³ ê°€" in th_text:
                                prev_high = _to_float(td_text)
                            elif "ì €ê°€" in th_text:
                                prev_low = _to_float(td_text)
                            elif "ì¢…ê°€" in th_text:
                                prev_close = _to_float(td_text)
                        # Early exit if we found all three
                        if prev_high and prev_low and prev_close:
                            break
        
        # Quick fallback: estimate from current price if prev_close not found
        if not prev_close and price > 0:
            if change != 0:
                prev_close = price - change
            else:
                prev_close = price
        
        # Calculate pivot points immediately (don't wait for high/low)
        pivot_data = None
        if prev_close:
            # Use estimated high/low if not available (faster than searching more tables)
            if not prev_high:
                prev_high = prev_close * 1.05
            if not prev_low:
                prev_low = prev_close * 0.95
            pivot_data = calculate_pivot_points(prev_high, prev_low, prev_close)
        
        # Only search other tables if we still need high/low (optional, non-blocking)
        if not (prev_high and prev_low) and summary_table:
            # Quick scan of other tables (limited search for speed)
            all_tables = soup.select("table.type_1, table.tb_type1")[:2]  # Limit to 2 tables
            for table in all_tables:
                rows = table.select("tr")[:10]  # Limit to first 10 rows
                for row in rows:
                    cells = row.select("th, td")
                    for i, cell in enumerate(cells):
                        cell_text = cell.get_text(strip=True)
                        if "ì „ì¼" in cell_text and i + 1 < len(cells):
                            if "ê³ ê°€" in cell_text and not prev_high:
                                prev_high = _to_float(cells[i + 1].get_text(strip=True))
                            elif "ì €ê°€" in cell_text and not prev_low:
                                prev_low = _to_float(cells[i + 1].get_text(strip=True))
                        # Early exit if found
                        if prev_high and prev_low:
                            break
                    if prev_high and prev_low:
                        break
                if prev_high and prev_low:
                    break
            # Recalculate pivot if we found better high/low values
            if (prev_high and prev_low and prev_close and 
                (prev_high != prev_close * 1.05 or prev_low != prev_close * 0.95)):
                pivot_data = calculate_pivot_points(prev_high, prev_low, prev_close)
        
        # Fetch news from news section - improved parsing with more selectors
        news = []
        # Try multiple selectors for news (expanded list)
        news_selectors = [
            "div.news_area ul li a",
            "div#news ul li a",
            "table.news_table a",
            "div.section.news ul li a",
            "div.news_area a",
            "ul.news_list a",
            "div.news a",
            "dl.news_list dt a",
            "div.tab_con1 ul li a",
            "div.tab_con ul li a",
            "div.news_wrap ul li a",
            "div.news_list ul li a",
            "table.type_2 a[href*='news']",
            "div.cmp_news ul li a",
            "a[href*='/item/news']",  # Direct news links
            "a[href*='news.naver.com']",  # External news links
        ]
        for selector in news_selectors:
            news_items = soup.select(selector)
            if news_items:
                for item in news_items[:15]:  # Check more items
                    title = item.get_text(strip=True)
                    href = item.get("href", "")
                    # More lenient title filter - accept any meaningful title
                    if title and len(title) > 2 and not any(skip in title for skip in ["ë”ë³´ê¸°", "ì „ì²´ë³´ê¸°", "â–¼", "â–²", "í¼ì¹˜ê¸°"]):
                        # Clean title: ensure proper UTF-8 encoding
                        try:
                            # BeautifulSoup should already handle encoding, but ensure it's clean
                            title_clean = title.strip()
                            # Remove any control characters that might cause issues
                            title_clean = ''.join(char for char in title_clean if ord(char) >= 32 or char in '\n\r\t')
                        except Exception:
                            title_clean = title.strip()
                        
                        # Extract date
                        date = ""
                        parent = item.parent
                        if parent:
                            date_el = parent.select_one("span.date, span.time, em.date, span.info, em.info, span.txt")
                            if date_el:
                                date = date_el.get_text(strip=True)
                            # Also check siblings
                            for sibling in parent.find_next_siblings():
                                if sibling.name in ["span", "em"] and ("date" in sibling.get("class", []) or "time" in sibling.get("class", [])):
                                    date = sibling.get_text(strip=True)
                                    break
                            # Check parent's parent for date
                            if not date and parent.parent:
                                date_el = parent.parent.select_one("span.date, span.time, em.date, em.info, span.txt")
                                if date_el:
                                    date = date_el.get_text(strip=True)
                        
                        # Build full URL
                        if href.startswith("/"):
                            full_url = f"https://finance.naver.com{href}"
                        elif href.startswith("http"):
                            full_url = href
                        elif href:
                            full_url = f"https://finance.naver.com/{href}"
                        else:
                            continue  # Skip if no valid href
                        
                        # Avoid duplicates
                        if not any(n.get("url") == full_url for n in news):
                            # Ensure proper UTF-8 encoding for title
                            try:
                                # Clean title: remove any invalid characters
                                title_clean = title.encode('utf-8', errors='ignore').decode('utf-8')
                                news.append({
                                    "title": title_clean,
                                    "date": date,
                                    "url": full_url,
                                })
                            except Exception:
                                # Fallback: use original title
                                news.append({
                                    "title": title,
                                    "date": date,
                                    "url": full_url,
                                })
                            if len(news) >= 5:  # Stop at 5 news items
                                break
                if len(news) >= 5:
                    break  # Found enough news, stop trying other selectors
        
        if news:
            print(f"[{code}] Found {len(news)} news items")
        else:
            print(f"[{code}] No news found in main page")
        
        # If no news found, try fetching from news page (parallel fetch for speed)
        if not news:
            try:
                # Use shorter timeout for news page
                news_res = await client.get(
                    f"https://finance.naver.com/item/news.naver?code={code}",
                    follow_redirects=True,
                    timeout=10.0
                )
                news_res.encoding = "euc-kr"
                news_html = news_res.text
                news_soup = BeautifulSoup(news_html, "html.parser")
                # More comprehensive selectors for news page
                news_items = news_soup.select(
                    "dl dt a, table.news_table a, ul.news_list a, "
                    "div.news_area ul li a, div#news ul li a, "
                    "div.tab_con1 ul li a, div.news_list ul li a"
                )
                for item in news_items[:10]:
                    title = item.get_text(strip=True)
                    href = item.get("href", "")
                    if title and len(title) > 3 and not title.startswith("ë”ë³´ê¸°"):
                        # Clean title: ensure proper UTF-8 encoding
                        try:
                            title_clean = title.strip()
                            # Remove any control characters that might cause issues
                            title_clean = ''.join(char for char in title_clean if ord(char) >= 32 or char in '\n\r\t')
                        except Exception:
                            title_clean = title.strip()
                        
                        if href.startswith("/"):
                            full_url = f"https://finance.naver.com{href}"
                        elif href.startswith("http"):
                            full_url = href
                        elif href:
                            full_url = f"https://finance.naver.com/{href}"
                        else:
                            continue
                        
                        # Avoid duplicates
                        if not any(n.get("url") == full_url for n in news):
                            news.append({
                                "title": title_clean,
                                "date": "",
                                "url": full_url,
                            })
                            if len(news) >= 5:
                                break
            except Exception as e:
                print(f"Warning: Failed to fetch news page for {code}: {e}")
                # Continue without news - don't block the response
        
        # Financial summary (ì¬ë¬´ ìš”ì•½) - parse from QUARTERLY financial table (not annual)
        # Try main page first (already loaded) for speed
        financials = []
        # First try main page (already loaded) - prioritize QUARTERLY tables over annual
        # Look for quarterly table first (ìµœê·¼ ë¶„ê¸° ì‹¤ì )
        fin_tables = soup.select("table.type_2, table.tb_type1, table.tb_type1_ifrs, table.sise")
        
        # Separate quarterly and annual tables
        quarterly_tables = []
        annual_tables = []
        
        for table in fin_tables:
            # Check caption or nearby text to identify table type
            caption = table.select_one("caption")
            caption_text = caption.get_text(strip=True) if caption else ""
            
            # Check parent div or h4 for table title
            parent = table.find_parent(["div", "section"])
            parent_text = parent.get_text(strip=True) if parent else ""
            
            # Check if this is a quarterly table (ë¶„ê¸°)
            if "ë¶„ê¸°" in caption_text or "ë¶„ê¸°" in parent_text:
                quarterly_tables.append(table)
            # Check if this is an annual table (ì—°ê°„) - we want to skip this
            elif "ì—°ê°„" in caption_text or "ì—°ê°„" in parent_text:
                annual_tables.append(table)
            else:
                # If unclear, check column headers for quarterly patterns
                # ë¶„ê¸° ì‹¤ì : 03, 06, 09, 12ì›”ì´ ì„ì—¬ ìˆì–´ì•¼ í•¨
                # ì—°ê°„ ì‹¤ì : ëª¨ë“  ì»¬ëŸ¼ì´ 12ì›”ì´ë©´ ì—°ê°„
                thead = table.select_one("thead")
                if thead:
                    headers = thead.select("th")
                    header_texts = [h.get_text(strip=True) for h in headers]
                    # Extract all date periods from headers
                    date_periods = []
                    for h_text in header_texts:
                        period_match = re.match(r'(\d{4})\.(\d{1,2})', h_text)
                        if period_match:
                            year = int(period_match.group(1))
                            month = int(period_match.group(2))
                            date_periods.append((year, month))
                    
                    if len(date_periods) > 0:
                        # Check if all months are December (ì—°ê°„ ì‹¤ì  íŒ¨í„´)
                        all_december = all(month == 12 for _, month in date_periods)
                        if all_december:
                            # ì—°ê°„ ì‹¤ì  í…Œì´ë¸”ë¡œ ë¶„ë¥˜
                            annual_tables.append(table)
                        else:
                            # 03, 06, 09, 12ì›”ì´ ì„ì—¬ ìˆìœ¼ë©´ ë¶„ê¸° ì‹¤ì 
                            months = [month for _, month in date_periods]
                            has_quarterly_months = any(m in [3, 6, 9, 12] for m in months)
                            if has_quarterly_months:
                                quarterly_tables.append(table)
                            else:
                                # ë¶ˆëª…í™•í•œ ê²½ìš° ì—°ê°„ìœ¼ë¡œ ë¶„ë¥˜ (ì•ˆì „í•˜ê²Œ)
                                annual_tables.append(table)
                else:
                    # If no thead, check first row
                    first_row = table.select_one("tr")
                    if first_row:
                        first_row_ths = first_row.select("th")
                        date_periods = []
                        for th in first_row_ths:
                            h_text = th.get_text(strip=True)
                            period_match = re.match(r'(\d{4})\.(\d{1,2})', h_text)
                            if period_match:
                                year = int(period_match.group(1))
                                month = int(period_match.group(2))
                                date_periods.append((year, month))
                        
                        if len(date_periods) > 0:
                            all_december = all(month == 12 for _, month in date_periods)
                            if all_december:
                                annual_tables.append(table)
                            else:
                                months = [month for _, month in date_periods]
                                has_quarterly_months = any(m in [3, 6, 9, 12] for m in months)
                                if has_quarterly_months:
                                    quarterly_tables.append(table)
                                else:
                                    annual_tables.append(table)
        
        # Process quarterly tables first (ìš°ì„ ìˆœìœ„)
        for table in quarterly_tables:
            # ì»¬ëŸ¼ í—¤ë” ì°¾ê¸° (scope="col" ë˜ëŠ” thead ë‚´ë¶€)
            thead = table.select_one("thead")
            col_headers = []
            if thead:
                col_headers = thead.select("th[scope='col'], th")
            else:
                # theadê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ í–‰ì˜ thë¥¼ ì»¬ëŸ¼ í—¤ë”ë¡œ ê°„ì£¼
                first_row = table.select_one("tr")
                if first_row:
                    col_headers = first_row.select("th")
            
            col_header_texts = [h.get_text(strip=True) for h in col_headers]
            
            # í–‰ í—¤ë”ì—ì„œ ë§¤ì¶œì•¡/ì˜ì—…ì´ìµ ì°¾ê¸° (scope="row")
            # ìš°ì„ ìˆœìœ„: "(ì–µì›)" ë‹¨ìœ„ê°€ ìˆëŠ” ì ˆëŒ€ê°’ ë°ì´í„°ë§Œ (ë¹„ìœ¨ ë°ì´í„° ì œì™¸)
            rows = table.select("tr")
            sales_row_idx = None
            profit_row_idx = None
            
            for i, row in enumerate(rows):
                row_headers = row.select("th[scope='row'], th.h_th2")
                for rh in row_headers:
                    rh_text = rh.get_text(strip=True)
                    # ë§¤ì¶œì•¡: "(ì–µì›)" ë‹¨ìœ„ê°€ ìˆëŠ” ê²ƒë§Œ (ë¹„ìœ¨ ì œì™¸)
                    if "ë§¤ì¶œì•¡" in rh_text and "(ì–µì›)" in rh_text:
                        if sales_row_idx is None:  # First match takes priority
                            sales_row_idx = i
                    elif "ë§¤ì¶œì•¡" in rh_text and "ë§¤ì¶œì›ê°€" not in rh_text and "%" not in rh_text and "ë¥ " not in rh_text:
                        # Fallback: ë§¤ì¶œì•¡ì´ì§€ë§Œ ë¹„ìœ¨ì´ ì•„ë‹Œ ê²½ìš°
                        if sales_row_idx is None:
                            sales_row_idx = i
                    # ì˜ì—…ì´ìµ: "(ì–µì›)" ë‹¨ìœ„ê°€ ìˆëŠ” ê²ƒë§Œ (ë¹„ìœ¨ ì œì™¸)
                    elif ("ì˜ì—…ì´ìµ" in rh_text or "ì˜ì—…ì†ìµ" in rh_text) and "(ì–µì›)" in rh_text:
                        if profit_row_idx is None:  # First match takes priority
                            profit_row_idx = i
                    elif ("ì˜ì—…ì´ìµ" in rh_text or "ì˜ì—…ì†ìµ" in rh_text) and "%" not in rh_text and "ë¥ " not in rh_text:
                        # Fallback: ì˜ì—…ì´ìµì´ì§€ë§Œ ë¹„ìœ¨ì´ ì•„ë‹Œ ê²½ìš°
                        if profit_row_idx is None:
                            profit_row_idx = i
            
            # ë§¤ì¶œì•¡/ì˜ì—…ì´ìµ í–‰ì´ ìˆìœ¼ë©´ íŒŒì‹±
            if sales_row_idx is not None or profit_row_idx is not None:
                # ì»¬ëŸ¼ í—¤ë”ì—ì„œ ê¸°ê°„ ì •ë³´ ì¶”ì¶œ (YYYY.MM í˜•ì‹)
                # theadì˜ th[scope='col']ì—ì„œ ë‚ ì§œ í—¤ë” ì°¾ê¸°
                periods = []
                period_col_indices = []  # ê° periodì˜ ì‹¤ì œ ì»¬ëŸ¼ ì¸ë±ìŠ¤
                
                # theadì—ì„œ ì§ì ‘ ì»¬ëŸ¼ í—¤ë”ì™€ ì¸ë±ìŠ¤ ë§¤í•‘
                if thead:
                    thead_rows = thead.select("tr")
                    for thead_row in thead_rows:
                        thead_ths = thead_row.select("th[scope='col'], th")
                        for col_idx, th in enumerate(thead_ths):
                            h_text = th.get_text(strip=True)
                            # (E)ê°€ í¬í•¨ëœ ì»¬ëŸ¼ì€ ì™„ì „íˆ ì œì™¸, ì‹¤ì œ ë°ì´í„°ë§Œ ì‚¬ìš©
                            if re.match(r'\d{4}\.\d{1,2}', h_text) and "(E)" not in h_text and "(e)" not in h_text:
                                # YYYY.MM í˜•ì‹ë§Œ ì¶”ì¶œ
                                period_match = re.match(r'(\d{4}\.\d{1,2})', h_text)
                                if period_match:
                                    period = period_match.group(1)
                                    if period not in periods:
                                        periods.append(period)
                                        period_col_indices.append(col_idx)
                else:
                    # theadê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ í–‰ì˜ thì—ì„œ ì°¾ê¸°
                    first_row = table.select_one("tr")
                    if first_row:
                        first_row_ths = first_row.select("th")
                        for col_idx, th in enumerate(first_row_ths):
                            h_text = th.get_text(strip=True)
                            # (E)ê°€ í¬í•¨ëœ ì»¬ëŸ¼ì€ ì™„ì „íˆ ì œì™¸, ì‹¤ì œ ë°ì´í„°ë§Œ ì‚¬ìš©
                            if re.match(r'\d{4}\.\d{1,2}', h_text) and "(E)" not in h_text and "(e)" not in h_text:
                                period_match = re.match(r'(\d{4}\.\d{1,2})', h_text)
                                if period_match:
                                    period = period_match.group(1)
                                    if period not in periods:
                                        periods.append(period)
                                        period_col_indices.append(col_idx)
                
                # ìµœê·¼ 4ê°œ ê¸°ê°„ë§Œ (ìµœì‹ ìˆœ) - ë‚ ì§œë¥¼ íŒŒì‹±í•´ì„œ ì •ë ¬
                # ë‚ ì§œ í˜•ì‹: YYYY.MM ë˜ëŠ” YYYY.MM.DD
                def parse_period(period_str):
                    """Parse period string to tuple for sorting (year, month)"""
                    match = re.match(r'(\d{4})\.(\d{1,2})', period_str)
                    if match:
                        return (int(match.group(1)), int(match.group(2)))
                    return (0, 0)
                
                # Sort periods by date (newest first), then take first 4
                period_data = list(zip(periods, period_col_indices))
                period_data.sort(key=lambda x: parse_period(x[0]), reverse=True)  # ìµœì‹ ìˆœ
                period_data = period_data[:4]  # ìµœê·¼ 4ê°œë§Œ
                
                # Unzip back to lists
                periods = [p[0] for p in period_data]
                period_col_indices = [p[1] for p in period_data]
                
                # ë§¤ì¶œì•¡/ì˜ì—…ì´ìµ í–‰ì˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                for period_idx, period in enumerate(periods):
                    sales = 0.0
                    profit = 0.0
                    
                    # ì»¬ëŸ¼ ì¸ë±ìŠ¤ ì‚¬ìš© (theadì—ì„œ ì°¾ì€ ì •í™•í•œ ì¸ë±ìŠ¤)
                    if period_idx < len(period_col_indices):
                        col_idx = period_col_indices[period_idx]
                    else:
                        # Fallback: period_idx + 1 (ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ í–‰ í—¤ë”ì¼ ìˆ˜ ìˆìŒ)
                        col_idx = period_idx + 1
                    
                    # ë§¤ì¶œì•¡ í–‰ì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸°
                    if sales_row_idx is not None and sales_row_idx < len(rows):
                        sales_row = rows[sales_row_idx]
                        sales_tds = sales_row.select("td")
                        if col_idx < len(sales_tds):
                            sales = _to_float(sales_tds[col_idx].get_text(strip=True))
                    
                    # ì˜ì—…ì´ìµ í–‰ì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸°
                    if profit_row_idx is not None and profit_row_idx < len(rows):
                        profit_row = rows[profit_row_idx]
                        profit_tds = profit_row.select("td")
                        if col_idx < len(profit_tds):
                            profit = _to_float(profit_tds[col_idx].get_text(strip=True))
                    
                    # ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€ (salesì™€ profitì´ ëª¨ë‘ 0ì´ë©´ ì œì™¸)
                    # ë‹¨, ìŒìˆ˜ ì˜ì—…ì´ìµì€ ìœ íš¨í•œ ë°ì´í„°ì´ë¯€ë¡œ í¬í•¨
                    if sales != 0 or profit != 0:
                        financials.append({
                            "period": period,
                            "sales": sales,
                            "operating_profit": profit,
                        })
                
                if len(financials) > 0:
                    break
            
            # Skip fallback for this table - we already processed quarterly tables above
        
        # If no quarterly data found, try other tables (but skip annual tables)
        # ì—°ê°„ ì‹¤ì  í…Œì´ë¸”ì€ ì™„ì „íˆ ì œì™¸
        if len(financials) == 0:
            for table in fin_tables:
                # Skip if this is an annual table (ì´ë¯¸ ë¶„ë¥˜ëœ ì—°ê°„ í…Œì´ë¸” ì œì™¸)
                if table in annual_tables:
                    continue
                
                # Skip if this is an annual table (í…ìŠ¤íŠ¸ ê¸°ë°˜ ì²´í¬)
                caption = table.select_one("caption")
                caption_text = caption.get_text(strip=True) if caption else ""
                parent = table.find_parent(["div", "section"])
                parent_text = parent.get_text(strip=True) if parent else ""
                if "ì—°ê°„" in caption_text or "ì—°ê°„" in parent_text:
                    continue  # Skip annual tables
                
                # Try the same parsing logic
                thead = table.select_one("thead")
                col_headers = []
                if thead:
                    col_headers = thead.select("th[scope='col'], th")
                else:
                    first_row = table.select_one("tr")
                    if first_row:
                        col_headers = first_row.select("th")
                
                col_header_texts = [h.get_text(strip=True) for h in col_headers]
                rows = table.select("tr")
                sales_row_idx = None
                profit_row_idx = None
                
                for i, row in enumerate(rows):
                    row_headers = row.select("th[scope='row'], th.h_th2")
                    for rh in row_headers:
                        rh_text = rh.get_text(strip=True)
                        if "ë§¤ì¶œì•¡" in rh_text and "(ì–µì›)" in rh_text:
                            if sales_row_idx is None:
                                sales_row_idx = i
                        elif "ë§¤ì¶œì•¡" in rh_text and "ë§¤ì¶œì›ê°€" not in rh_text and "%" not in rh_text and "ë¥ " not in rh_text:
                            if sales_row_idx is None:
                                sales_row_idx = i
                        elif ("ì˜ì—…ì´ìµ" in rh_text or "ì˜ì—…ì†ìµ" in rh_text) and "(ì–µì›)" in rh_text:
                            if profit_row_idx is None:
                                profit_row_idx = i
                        elif ("ì˜ì—…ì´ìµ" in rh_text or "ì˜ì—…ì†ìµ" in rh_text) and "%" not in rh_text and "ë¥ " not in rh_text:
                            if profit_row_idx is None:
                                profit_row_idx = i
                
                if sales_row_idx is not None or profit_row_idx is not None:
                    # Same parsing logic as above
                    periods = []
                    period_col_indices = []
                    
                    if thead:
                        thead_rows = thead.select("tr")
                        for thead_row in thead_rows:
                            thead_ths = thead_row.select("th[scope='col'], th")
                            for col_idx, th in enumerate(thead_ths):
                                h_text = th.get_text(strip=True)
                                # (E)ê°€ í¬í•¨ëœ ì»¬ëŸ¼ì€ ì™„ì „íˆ ì œì™¸, ì‹¤ì œ ë°ì´í„°ë§Œ ì‚¬ìš©
                                if re.match(r'\d{4}\.\d{1,2}', h_text) and "(E)" not in h_text and "(e)" not in h_text:
                                    period_match = re.match(r'(\d{4}\.\d{1,2})', h_text)
                                    if period_match:
                                        period = period_match.group(1)
                                        if period not in periods:
                                            periods.append(period)
                                            period_col_indices.append(col_idx)
                    
                    # ìµœê·¼ 4ê°œ ê¸°ê°„ë§Œ (ìµœì‹ ìˆœ) - ë‚ ì§œë¥¼ íŒŒì‹±í•´ì„œ ì •ë ¬
                    def parse_period(period_str):
                        """Parse period string to tuple for sorting (year, month)"""
                        match = re.match(r'(\d{4})\.(\d{1,2})', period_str)
                        if match:
                            return (int(match.group(1)), int(match.group(2)))
                        return (0, 0)
                    
                    # Sort periods by date (newest first), then take first 4
                    period_data = list(zip(periods, period_col_indices))
                    period_data.sort(key=lambda x: parse_period(x[0]), reverse=True)  # ìµœì‹ ìˆœ
                    period_data = period_data[:4]  # ìµœê·¼ 4ê°œë§Œ
                    
                    # Unzip back to lists
                    periods = [p[0] for p in period_data]
                    period_col_indices = [p[1] for p in period_data]
                    
                    for period_idx, period in enumerate(periods):
                        sales = 0.0
                        profit = 0.0
                        
                        if period_idx < len(period_col_indices):
                            col_idx = period_col_indices[period_idx]
                        else:
                            col_idx = period_idx + 1
                        
                        if sales_row_idx is not None and sales_row_idx < len(rows):
                            sales_row = rows[sales_row_idx]
                            sales_tds = sales_row.select("td")
                            if col_idx < len(sales_tds):
                                sales = _to_float(sales_tds[col_idx].get_text(strip=True))
                        
                        if profit_row_idx is not None and profit_row_idx < len(rows):
                            profit_row = rows[profit_row_idx]
                            profit_tds = profit_row.select("td")
                            if col_idx < len(profit_tds):
                                profit = _to_float(profit_tds[col_idx].get_text(strip=True))
                        
                        # ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                        if sales != 0 or profit != 0:
                            financials.append({
                                "period": period,
                                "sales": sales,
                                "operating_profit": profit,
                            })
                    
                    if len(financials) > 0:
                        break
        
        # Convert financials from list to date-keyed object structure
        # Structure: {"2024.12": {"sales": 195, "operating_profit": -10}, ...}
        financials_dict = {}
        if financials:
            def parse_period_for_sort(period_str):
                """Parse period string to tuple for sorting (year, month)"""
                match = re.match(r'(\d{4})\.(\d{1,2})', period_str)
                if match:
                    return (int(match.group(1)), int(match.group(2)))
                return (0, 0)
            
            # Sort by period (newest first) to ensure consistent ordering
            financials.sort(key=lambda x: parse_period_for_sort(x.get("period", "")), reverse=True)
            
            # Convert to date-keyed dictionary
            for f in financials:
                period = f.get("period", "")
                if period:
                    financials_dict[period] = {
                        "sales": f.get("sales", 0.0),
                        "operating_profit": f.get("operating_profit", 0.0),
                    }
            
            print(f"[{code}] Found {len(financials_dict)} financial records (quarterly)")
        else:
            print(f"[{code}] No quarterly financial data found in main page")
        
        # Use dictionary structure instead of list (empty dict becomes None)
        financials = financials_dict if financials_dict else None
        
        # Only try other pages if not found in main page (to speed up)
        # Skip - we prioritize quarterly tables from main page
        
        # Investor trends (íˆ¬ììë³„ ë§¤ë§¤ë™í–¥) - parse from investor table
        # Try main page first (already loaded) for speed
        investor_trends = []
        inv_tables = soup.select("table.type_2, table.tb_type1, table.type_1, table.sise")
        
        # ìš°ì„ ìˆœìœ„: summary ì†ì„±ì— "ì™¸êµ­ì¸" ë˜ëŠ” "ê¸°ê´€" ë˜ëŠ” "ìˆœë§¤ë§¤"ê°€ í¬í•¨ëœ í…Œì´ë¸”
        priority_tables = []
        other_tables = []
        
        for table in inv_tables:
            table_summary = table.get("summary", "")
            caption = table.select_one("caption")
            caption_text = caption.get_text(strip=True) if caption else ""
            
            # ìš°ì„ ìˆœìœ„ í…Œì´ë¸”: summaryë‚˜ captionì— íˆ¬ìì ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš°
            if any(keyword in table_summary or keyword in caption_text 
                   for keyword in ["ì™¸êµ­ì¸", "ê¸°ê´€", "ìˆœë§¤ë§¤", "ë§¤ë§¤ë™í–¥", "íˆ¬ìì"]):
                priority_tables.append(table)
            else:
                other_tables.append(table)
        
        # ìš°ì„ ìˆœìœ„ í…Œì´ë¸”ë¶€í„° ì²˜ë¦¬
        tables_to_check = priority_tables + other_tables
        
        for table in tables_to_check:
            headers = table.select("th")
            header_texts = [h.get_text(strip=True) for h in headers]
            has_institution = any("ê¸°ê´€" in h or "ê¸°ê´€íˆ¬ìì" in h for h in header_texts)
            has_foreigner = any("ì™¸êµ­ì¸" in h or "ì™¸êµ­ì¸íˆ¬ìì" in h for h in header_texts)
            
            # í˜¸ê°€ ì •ë³´ í…Œì´ë¸” ì œì™¸
            table_summary = table.get("summary", "")
            if "í˜¸ê°€ ì •ë³´" in table_summary or "í˜¸ê°€ì •ë³´" in table_summary:
                continue
            
            if has_institution and has_foreigner:
                # ì»¬ëŸ¼ í—¤ë”ë§Œ ì°¾ê¸° (scope="col" ë˜ëŠ” thead ë‚´ë¶€)
                inv_thead = table.select_one("thead")
                col_headers = []
                if inv_thead:
                    # theadì˜ ëª¨ë“  trì—ì„œ th ì°¾ê¸°
                    thead_rows = inv_thead.select("tr")
                    for thead_row in thead_rows:
                        col_headers.extend(thead_row.select("th[scope='col'], th"))
                else:
                    # theadê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ í–‰ì˜ thë¥¼ ì»¬ëŸ¼ í—¤ë”ë¡œ ê°„ì£¼
                    first_row = table.select_one("tr")
                    if first_row:
                        col_headers = first_row.select("th")
                
                col_header_texts = [h.get_text(strip=True) for h in col_headers]
                
                # í—¤ë”ì—ì„œ ì •í™•í•œ ì»¬ëŸ¼ ì¸ë±ìŠ¤ ì°¾ê¸°
                # í…Œì´ë¸” êµ¬ì¡°: ë‚ ì§œ, ì¢…ê°€, ì „ì¼ë¹„, ë“±ë½ë¥ , ê±°ë˜ëŸ‰, ê¸°ê´€(ìˆœë§¤ë§¤ëŸ‰), ì™¸êµ­ì¸(ìˆœë§¤ë§¤ëŸ‰), ì™¸êµ­ì¸(ë³´ìœ ì£¼ìˆ˜), ì™¸êµ­ì¸(ë³´ìœ ìœ¨)
                date_idx = None
                institution_idx = None
                foreigner_idx = None
                foreigner_shares_idx = None
                foreigner_ratio_idx = None
                
                # 2í–‰ í—¤ë” êµ¬ì¡° ì²˜ë¦¬: ì²« ë²ˆì§¸ í–‰ê³¼ ë‘ ë²ˆì§¸ í–‰ ëª¨ë‘ í™•ì¸
                for i, header in enumerate(col_header_texts):
                    header_lower = header.lower()
                    if "ë‚ ì§œ" in header or "ì¼ì" in header or "date" in header_lower:
                        date_idx = i
                    elif "ê¸°ê´€" in header and "ìˆœë§¤ë§¤" in header:
                        institution_idx = i
                    elif "ì™¸êµ­ì¸" in header and "ìˆœë§¤ë§¤" in header:
                        foreigner_idx = i
                    elif "ì™¸êµ­ì¸" in header and ("ë³´ìœ ì£¼ìˆ˜" in header or "ë³´ìœ " in header) and "ìœ¨" not in header:
                        foreigner_shares_idx = i
                    elif "ì™¸êµ­ì¸" in header and ("ë³´ìœ ìœ¨" in header or "ìœ¨" in header):
                        foreigner_ratio_idx = i
                
                # Fallback: í—¤ë” í…ìŠ¤íŠ¸ê°€ ì •í™•íˆ ë§¤ì¹­ë˜ì§€ ì•Šì€ ê²½ìš° ìœ„ì¹˜ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì •
                # ì¼ë°˜ì ì¸ ìˆœì„œ: ë‚ ì§œ(0), ì¢…ê°€(1), ì „ì¼ë¹„(2), ë“±ë½ë¥ (3), ê±°ë˜ëŸ‰(4), ê¸°ê´€(5), ì™¸êµ­ì¸(6), ì™¸êµ­ì¸ë³´ìœ ì£¼ìˆ˜(7), ì™¸êµ­ì¸ë³´ìœ ìœ¨(8)
                if institution_idx is None and len(col_header_texts) > 5:
                    # "ê¸°ê´€"ì´ í¬í•¨ëœ í—¤ë” ì°¾ê¸°
                    for i, header in enumerate(col_header_texts):
                        if "ê¸°ê´€" in header and institution_idx is None:
                            institution_idx = i
                            break
                
                if foreigner_idx is None and len(col_header_texts) > 6:
                    # "ì™¸êµ­ì¸"ì´ í¬í•¨ë˜ê³  "ìˆœë§¤ë§¤"ê°€ ìˆëŠ” í—¤ë” ì°¾ê¸°
                    for i, header in enumerate(col_header_texts):
                        if "ì™¸êµ­ì¸" in header and "ìˆœë§¤ë§¤" in header and foreigner_idx is None:
                            foreigner_idx = i
                            break
                
                if foreigner_shares_idx is None and len(col_header_texts) > 7:
                    # "ì™¸êµ­ì¸"ì´ í¬í•¨ë˜ê³  "ë³´ìœ ì£¼ìˆ˜"ê°€ ìˆëŠ” í—¤ë” ì°¾ê¸°
                    for i, header in enumerate(col_header_texts):
                        if "ì™¸êµ­ì¸" in header and ("ë³´ìœ ì£¼ìˆ˜" in header or "ë³´ìœ " in header) and "ìœ¨" not in header and foreigner_shares_idx is None:
                            foreigner_shares_idx = i
                            break
                
                if foreigner_ratio_idx is None and len(col_header_texts) > 8:
                    # "ì™¸êµ­ì¸"ì´ í¬í•¨ë˜ê³  "ë³´ìœ ìœ¨"ì´ ìˆëŠ” í—¤ë” ì°¾ê¸°
                    for i, header in enumerate(col_header_texts):
                        if "ì™¸êµ­ì¸" in header and ("ë³´ìœ ìœ¨" in header or "ìœ¨" in header) and foreigner_ratio_idx is None:
                            foreigner_ratio_idx = i
                            break
                
                rows = table.select("tr")
                for row in rows[1:]:  # Skip header
                    tds = row.select("td")
                    if len(tds) < 2:
                        continue
                    
                    # í—¤ë” ë§¤ì¹­ìœ¼ë¡œ ì •í™•í•œ ì»¬ëŸ¼ ì‚¬ìš©
                    if date_idx is not None and date_idx < len(tds):
                        date = tds[date_idx].get_text(strip=True)
                    else:
                        date = tds[0].get_text(strip=True)  # Fallback
                    
                    # Skip if date is empty or looks like a header
                    if not date or date in ["ë‚ ì§œ", "ì¼ì", "êµ¬ë¶„", "Date"]:
                        continue
                    
                    # ë‚ ì§œ í˜•ì‹ ê²€ì¦ (YYYY.MM.DD ë˜ëŠ” YYYY-MM-DD í˜•ì‹ë§Œ í—ˆìš©)
                    date_clean = date.strip() if date else ""
                    is_valid_date = False
                    if date_clean:
                        # YYYY.MM.DD ë˜ëŠ” YYYY-MM-DD í˜•ì‹ í™•ì¸
                        if re.match(r'\d{4}[\.-]\d{1,2}[\.-]\d{1,2}', date_clean):
                            is_valid_date = True
                        # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° ìŠ¤í‚µ (ì¢…ê°€ ë“±)
                        elif date_clean.replace(",", "").replace(".", "").replace("-", "").isdigit():
                            is_valid_date = False
                    
                    if not is_valid_date:
                        continue
                    
                    # í—¤ë” ë§¤ì¹­ìœ¼ë¡œ ê¸°ê´€/ì™¸êµ­ì¸ ê°’ ê°€ì ¸ì˜¤ê¸°
                    institution = 0
                    foreigner = 0
                    foreigner_shares = 0
                    foreigner_ratio = 0.0
                    
                    if institution_idx is not None and institution_idx < len(tds):
                        institution_text = tds[institution_idx].get_text(strip=True)
                        institution = _to_int(institution_text)
                    elif len(tds) > 5:
                        # Fallback: 6ë²ˆì§¸ ì»¬ëŸ¼(ì¸ë±ìŠ¤ 5)ì´ ê¸°ê´€ì¼ ê°€ëŠ¥ì„±
                        institution = _to_int(tds[5].get_text(strip=True))
                    
                    if foreigner_idx is not None and foreigner_idx < len(tds):
                        foreigner_text = tds[foreigner_idx].get_text(strip=True)
                        foreigner = _to_int(foreigner_text)
                    elif len(tds) > 6:
                        # Fallback: 7ë²ˆì§¸ ì»¬ëŸ¼(ì¸ë±ìŠ¤ 6)ì´ ì™¸êµ­ì¸ ìˆœë§¤ë§¤ëŸ‰ì¼ ê°€ëŠ¥ì„±
                        foreigner = _to_int(tds[6].get_text(strip=True))
                    
                    if foreigner_shares_idx is not None and foreigner_shares_idx < len(tds):
                        foreigner_shares_text = tds[foreigner_shares_idx].get_text(strip=True)
                        foreigner_shares = _to_int(foreigner_shares_text)
                    elif len(tds) > 7:
                        # Fallback: 8ë²ˆì§¸ ì»¬ëŸ¼(ì¸ë±ìŠ¤ 7)ì´ ì™¸êµ­ì¸ ë³´ìœ ì£¼ìˆ˜ì¼ ê°€ëŠ¥ì„±
                        foreigner_shares = _to_int(tds[7].get_text(strip=True))
                    
                    if foreigner_ratio_idx is not None and foreigner_ratio_idx < len(tds):
                        foreigner_ratio_text = tds[foreigner_ratio_idx].get_text(strip=True)
                        foreigner_ratio = _to_float(foreigner_ratio_text)
                    elif len(tds) > 8:
                        # Fallback: 9ë²ˆì§¸ ì»¬ëŸ¼(ì¸ë±ìŠ¤ 8)ì´ ì™¸êµ­ì¸ ë³´ìœ ìœ¨ì¼ ê°€ëŠ¥ì„±
                        foreigner_ratio = _to_float(tds[8].get_text(strip=True))
                    
                    investor_trends.append({
                        "date": date_clean,
                        "institution": institution,
                        "foreigner": foreigner,
                        "foreigner_shares": foreigner_shares,
                        "foreigner_ratio": foreigner_ratio,
                    })
                    if len(investor_trends) >= 5:  # Recent 5 days
                        break
                if len(investor_trends) > 0:
                    break
        
        if investor_trends:
            print(f"[{code}] Found {len(investor_trends)} investor trend records")
        else:
            print(f"[{code}] No investor trend data found in main page")
        
        # Only try other pages if not found in main page (to speed up)
        if not investor_trends:
            investor_pages = [
                f"https://finance.naver.com/item/frgn.naver?code={code}",
            ]
            for inv_url in investor_pages:
                try:
                    inv_html = await _get(client, inv_url)
                    inv_soup = BeautifulSoup(inv_html, "html.parser")
                    inv_tables = inv_soup.select("table.type_2, table.tb_type1, table.sise, table.type_1")
                    for table in inv_tables:
                        headers = table.select("th")
                        header_texts = [h.get_text(strip=True) for h in headers]
                        has_institution = any("ê¸°ê´€" in h for h in header_texts)
                        has_foreigner = any("ì™¸êµ­ì¸" in h for h in header_texts)
                        
                        if has_institution and has_foreigner:
                            # ì»¬ëŸ¼ í—¤ë”ë§Œ ì°¾ê¸° (scope="col" ë˜ëŠ” thead ë‚´ë¶€)
                            inv_thead = table.select_one("thead")
                            col_headers = []
                            if inv_thead:
                                # theadì˜ ëª¨ë“  trì—ì„œ th ì°¾ê¸°
                                thead_rows = inv_thead.select("tr")
                                for thead_row in thead_rows:
                                    col_headers.extend(thead_row.select("th[scope='col'], th"))
                            else:
                                first_row = table.select_one("tr")
                                if first_row:
                                    col_headers = first_row.select("th")
                            
                            col_header_texts = [h.get_text(strip=True) for h in col_headers]
                            
                            # í—¤ë”ì—ì„œ ì •í™•í•œ ì»¬ëŸ¼ ì¸ë±ìŠ¤ ì°¾ê¸°
                            date_idx = None
                            institution_idx = None
                            foreigner_idx = None
                            foreigner_shares_idx = None
                            foreigner_ratio_idx = None
                            
                            for i, header in enumerate(col_header_texts):
                                header_lower = header.lower()
                                if "ë‚ ì§œ" in header or "ì¼ì" in header or "date" in header_lower:
                                    date_idx = i
                                elif "ê¸°ê´€" in header and "ìˆœë§¤ë§¤" in header:
                                    institution_idx = i
                                elif "ì™¸êµ­ì¸" in header and "ìˆœë§¤ë§¤" in header:
                                    foreigner_idx = i
                                elif "ì™¸êµ­ì¸" in header and ("ë³´ìœ ì£¼ìˆ˜" in header or "ë³´ìœ " in header) and "ìœ¨" not in header:
                                    foreigner_shares_idx = i
                                elif "ì™¸êµ­ì¸" in header and ("ë³´ìœ ìœ¨" in header or "ìœ¨" in header):
                                    foreigner_ratio_idx = i
                            
                            # Fallback: ìœ„ì¹˜ ê¸°ë°˜ ì¶”ì •
                            if institution_idx is None and len(col_header_texts) > 5:
                                for i, header in enumerate(col_header_texts):
                                    if "ê¸°ê´€" in header and institution_idx is None:
                                        institution_idx = i
                                        break
                            
                            if foreigner_idx is None and len(col_header_texts) > 6:
                                for i, header in enumerate(col_header_texts):
                                    if "ì™¸êµ­ì¸" in header and "ìˆœë§¤ë§¤" in header and foreigner_idx is None:
                                        foreigner_idx = i
                                        break
                            
                            if foreigner_shares_idx is None and len(col_header_texts) > 7:
                                for i, header in enumerate(col_header_texts):
                                    if "ì™¸êµ­ì¸" in header and ("ë³´ìœ ì£¼ìˆ˜" in header or "ë³´ìœ " in header) and "ìœ¨" not in header and foreigner_shares_idx is None:
                                        foreigner_shares_idx = i
                                        break
                            
                            if foreigner_ratio_idx is None and len(col_header_texts) > 8:
                                for i, header in enumerate(col_header_texts):
                                    if "ì™¸êµ­ì¸" in header and ("ë³´ìœ ìœ¨" in header or "ìœ¨" in header) and foreigner_ratio_idx is None:
                                        foreigner_ratio_idx = i
                                        break
                            
                            rows = table.select("tr")
                            for row in rows[1:]:  # Skip header
                                tds = row.select("td")
                                if len(tds) < 2:
                                    continue
                                
                                # í—¤ë” ë§¤ì¹­ìœ¼ë¡œ ì •í™•í•œ ì»¬ëŸ¼ ì‚¬ìš©
                                if date_idx is not None and date_idx < len(tds):
                                    date = tds[date_idx].get_text(strip=True)
                                else:
                                    date = tds[0].get_text(strip=True)  # Fallback
                                
                                # Skip if date is empty or looks like a header
                                if not date or date in ["ë‚ ì§œ", "ì¼ì", "êµ¬ë¶„", "Date"]:
                                    continue
                                
                                # ë‚ ì§œ í˜•ì‹ ê²€ì¦ (YYYY.MM.DD ë˜ëŠ” YYYY-MM-DD í˜•ì‹ë§Œ í—ˆìš©)
                                date_clean = date.strip() if date else ""
                                is_valid_date = False
                                if date_clean:
                                    # YYYY.MM.DD ë˜ëŠ” YYYY-MM-DD í˜•ì‹ í™•ì¸
                                    if re.match(r'\d{4}[\.-]\d{1,2}[\.-]\d{1,2}', date_clean):
                                        is_valid_date = True
                                    # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° ìŠ¤í‚µ (ì¢…ê°€ ë“±)
                                    elif date_clean.replace(",", "").replace(".", "").replace("-", "").isdigit():
                                        is_valid_date = False
                                
                                if not is_valid_date:
                                    continue
                                
                                institution = 0
                                foreigner = 0
                                foreigner_shares = 0
                                foreigner_ratio = 0.0
                                
                                if institution_idx is not None and institution_idx < len(tds):
                                    institution_text = tds[institution_idx].get_text(strip=True)
                                    institution = _to_int(institution_text)
                                elif len(tds) > 5:
                                    institution = _to_int(tds[5].get_text(strip=True))
                                
                                if foreigner_idx is not None and foreigner_idx < len(tds):
                                    foreigner_text = tds[foreigner_idx].get_text(strip=True)
                                    foreigner = _to_int(foreigner_text)
                                elif len(tds) > 6:
                                    foreigner = _to_int(tds[6].get_text(strip=True))
                                
                                if foreigner_shares_idx is not None and foreigner_shares_idx < len(tds):
                                    foreigner_shares_text = tds[foreigner_shares_idx].get_text(strip=True)
                                    foreigner_shares = _to_int(foreigner_shares_text)
                                elif len(tds) > 7:
                                    foreigner_shares = _to_int(tds[7].get_text(strip=True))
                                
                                if foreigner_ratio_idx is not None and foreigner_ratio_idx < len(tds):
                                    foreigner_ratio_text = tds[foreigner_ratio_idx].get_text(strip=True)
                                    foreigner_ratio = _to_float(foreigner_ratio_text)
                                elif len(tds) > 8:
                                    foreigner_ratio = _to_float(tds[8].get_text(strip=True))
                                
                                investor_trends.append({
                                    "date": date_clean,
                                    "institution": institution,
                                    "foreigner": foreigner,
                                    "foreigner_shares": foreigner_shares,
                                    "foreigner_ratio": foreigner_ratio,
                                })
                                if len(investor_trends) >= 5:  # Recent 5 days
                                    break
                            if len(investor_trends) > 0:
                                break
                            if len(investor_trends) > 0:
                                break
                    if len(investor_trends) > 0:
                        break
                except Exception as e:
                    print(f"Warning: Failed to fetch investor page {inv_url} for {code}: {e}")
                    continue
        
        return StockDetail(
            code=code,
            name=name,
            price=price,
            change=change,
            change_pct=change_pct,
            volume=volume,
            trade_value=trade_value,
            market=market,
            pivot=pivot_data["pivot"] if pivot_data else None,
            r1=pivot_data["r1"] if pivot_data else None,
            r2=pivot_data["r2"] if pivot_data else None,
            s1=pivot_data["s1"] if pivot_data else None,
            s2=pivot_data["s2"] if pivot_data else None,
            prev_high=prev_high,
            prev_low=prev_low,
            prev_close=prev_close,
            news=news if news else [],
            financials=financials,
            investor_trends=investor_trends,
        )
    except Exception as e:
        print(f"Error fetching stock detail for {code}: {e}")
        return None


